---
title: >-
 CogAgent, AutoWebGLM, Ferret-UI, OSWorld: GUIAgent之二三四
tags:
  - 计算机
  - 人工智能
  - 计算机
  - Reasoning
  - Computer Vision
  - GUI
categories: 论文阅读笔记
photo: "../../files/images/guiagent/ferret.png"
abbrlink: abea8da9
date: 2024-04-10 13:41:15
---

昨天apple出了个Ferret-UI VLM模型专门针对手机的理解任务，恰好上周看到了唐杰老师的AutoWebGLM，是让GLM LLM操作网页，再之前的CogAgent通过VLM可以同时操作手机、网页……最近一段时间通过操控GUI来实现操控手机、电脑的研究正在逐渐增加，来一起看一下他们都是怎么做的吧。参考文献：

> Every Step Counts: Growing General Vision Language Model to GUI Agent
>
> OSWORLD: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments
>
> CogAgent: A Visual Language Model for GUI Agents
>
> Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs
>
> AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent

<!-- more -->

## 何为GUI-Agent及其过去

GUI-Agent主要指的是：让大模型操纵手机、电脑，来自动化完成一些任务。从去年大家做LLM在ALFWorld、24点等传统的文本推理任务，到今年开始想着GUI领域的多模态推理，其实基本是一波人在研究，方法应该差的也不是很远。不过，在GUI领域看到Agent一步步的操作设备，确实是一件很“酷”的事情。

其实



## GUI-Agent in 2024



