---
title: 2024-06-06-insights
tags:
  - English
categories: Arxiv-Insights
total: 90
interesting: 1
read: 460
cite: 410
publish: 11
mathjax: true
hidden: true
abbrlink: 8f8d47f4
date: 2024-06-06 12:22:35
---

## [WINGS: Learning Multimodal LLMs without Text-only Forgetting](https://arxiv.org/pdf/2406.03496)

作者的目标是让VLM尽可能不遗忘纯文本领域的能力。作者提供了一个有趣的视角：作者发现对于多模态的输入，模型会更倾向于在attention中关注图片后面的文字

<img src="../../files/images/arxiv-insights/2024-06-03-06-07/wing.png">
