---
title: 2023-11-28-insights
tags:
  - English
categories: Arxiv-Insights
total: 87
interesting: 2
hidden: true
abbrlink: d4add1dd
date: 2023-11-28 11:48:42
---



## Data Diversity Matters for Robust Instruction Tuning

微软的研究。作者谈到在instruction tuning场景，训练数据的选择对下游任务很重要。同时数据选择时需要在数据的质量和数据的多样性上做出权衡，以前没有人系统的探索过这两点。

作者提出了一套Quality-Diversity Instruction Tuning (QDIT)框架，可以自动选择数据中quality/diversity的比重，发现由此训出来的SFT模型下限更高，同时平均表现也有提升。



## MoDS: Model-oriented Data Selection for Instruction Tuning

同样是对instruction tuning选取数据的论文。作者提了一个三阶段的方法：

1. 用一个quality evaluation model去选择高质量数据
2. 接下来设计一个算法从上一步的子集中进一步选取一个diversity不掉的subset
3. 训一个SFT模型，看看哪些样本是这个SFT模型不好学的，再进一步做出一个subset

最终作者说出来的4k的subset比原来的214k的instruction data效果要好

关于这种“用模型自己的Training Dynamics”作为一种筛数据指标的方法，我近期打算写一篇yejin choi的老论文的笔记，大家可以一起品味一下
